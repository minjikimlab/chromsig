{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d55445-6a90-4fd4-a432-dceb623e10a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(53961) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53962) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53963) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53964) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53965) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53966) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53967) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53968) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53969) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53970) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53971) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53972) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53973) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53974) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53975) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53976) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53977) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53978) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53979) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53980) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53981) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53982) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53983) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53984) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53985) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53986) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53987) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53988) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53989) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53990) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53991) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53992) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53993) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53994) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53995) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53996) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53997) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53998) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(53999) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(54000) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(54001) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(54002) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(54003) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(54004) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import pybedtools\n",
    "from pyBedGraph import BedGraph\n",
    "from pybedtools import BedTool\n",
    "from sys import argv\n",
    "import multiprocessing\n",
    "import defs_v2\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51cb236b-d544-4b61-8f26-9d2d231a2dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7508508\n",
      "648188\n"
     ]
    }
   ],
   "source": [
    "# FDR: 0.1\n",
    "# sample_size = 5000\n",
    "# For 'chr1':\n",
    "#   # Pass\n",
    "#   # Fail\n",
    "#   # Runtime/memory\n",
    "\n",
    "# Read in samples from bed/bedgraph file\n",
    "def read_gems(directory, file_name, chr_name):\n",
    "    \"\"\"\n",
    "    Read a GEM file of the form \"PlinePgem\".\n",
    "    Args:\n",
    "       directory (str): directory of the file location (ex: '/Users/kimm/')\n",
    "       file_name (str): name of the file (ex: 'SHG0008H.Fragnum_PlinePgem')\n",
    "    Returns:\n",
    "       in_gems (list): tab-separated lists of lists\n",
    "    \"\"\"\n",
    "    subset_gems = {}\n",
    "    cnt_all = 0\n",
    "    cnt_subset = 0\n",
    "    with open(directory + file_name) as f:\n",
    "        for line in f:\n",
    "            tmp = line.strip().split(\"\\t\")\n",
    "            if tmp[0] == chr_name:\n",
    "                subset_gems.setdefault(tmp[3].split(\"/\")[0], []).append(tmp)\n",
    "                cnt_subset += 1\n",
    "            cnt_all += 1\n",
    "        #in_gems = [line.strip().split(\"\\t\") for line in f]\n",
    "    gem_span = int(subset_gems[list(subset_gems.keys())[0]][0][2]) - int(subset_gems[list(subset_gems.keys())[0]][0][1])\n",
    "    return subset_gems, cnt_all, cnt_subset, gem_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4705c1-0a84-4b15-88ba-f79302acfefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c895c642-ed93-46f1-8fcf-724f394d5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the hg38.chrom.sizes file into a dictionary\n",
    "def read_chroms(directory, genome_name):\n",
    "    \"\"\"\n",
    "    Read a tab-delimited text file with list of chromosomes and their sizes.\n",
    "    Args:\n",
    "       directory (str): directory of the file location (ex: '/Users/kimm/')\n",
    "       genome_name (str): name of reference genome (ex: 'dm3', 'mm10', 'hg38', 'hg19', etc.)\n",
    "                        Note: must have a text file <genome_name>.chrom.sizes in the directory.\n",
    "    Returns:\n",
    "       chrom_dict (dictionary): tab-separated lists of lists\n",
    "    \"\"\"\n",
    "    chrom_dict = {}\n",
    "    with open(directory + genome_name + '.chrom.sizes') as f:\n",
    "        for line in f:\n",
    "            tmp_list = line.strip().split(\"\\t\")\n",
    "            chrom_dict[tmp_list[0]] = int(tmp_list[1])\n",
    "    return chrom_dict\n",
    "\n",
    "\n",
    "# Determine random start locations for samples to compare to observed sample\n",
    "# Gem span should be the same for all single-end fragments\n",
    "def random_loc_se(chrom_size, gem_span, chrom, sample_size, cov):\n",
    "    \"\"\"\n",
    "    Randomly locate GEM with same span in a chromosome sample_size times.\n",
    "    Args:\n",
    "       chrom_size (int): size of a given chromosome (ex: 23011544 if 'chr2L')\n",
    "       gem_span (int): GEM from start of first fragment to end of last fragment (ex: 5000)\n",
    "       sample_size (int): number of random locations to sample\n",
    "    Returns:\n",
    "       startpos (array): random integers array of length 'sample_size'\n",
    "    \"\"\"\n",
    "    np.random.seed(12345)\n",
    "    exp_enrich_lst = []\n",
    "    i = 0\n",
    "    while i < sample_size:\n",
    "        startpos = np.random.randint(low = 0, high = chrom_size - gem_span - 1)\n",
    "        current_frag = [chrom, startpos, startpos + gem_span]\n",
    "        exp_enrich = cov.stats(stat = 'max', intervals = [current_frag])[0]\n",
    "        #outfile.write(\"CurrentIndex: \" + str(i) + \"\\t\")\n",
    "        #outfile.write(\"Exp Enrichment: \" + str(exp_enrich) + \"\\n\")\n",
    "        #outfile.write(\"Current Pseudo: \" + str(pseudo) + \"\\n\")\n",
    "        if int(exp_enrich) == -1:\n",
    "            i -= 1\n",
    "        else:\n",
    "            exp_enrich_lst.append(exp_enrich)\n",
    "        #outfile.write(\"CurrentIndex SameCycle: \" + str(i) + \"\\t\")\n",
    "        #outfile.write(\"Exp Enrichment SameCycle: \" + str(exp_enrich) + \"\\n\")\n",
    "        #outfile.write(\"Current Pseudo SameCycle: \" + str(pseudo) + \"\\n\")\n",
    "        i += 1\n",
    "    return exp_enrich_lst\n",
    "    \n",
    "'''\n",
    "def random_loc_pe(subset_gems, chrom_size, chrom, sample_size, cov):\n",
    "    print(\"In old random_loc\\n\")\n",
    "    np.random.seed(12345)\n",
    "    exp_enrich_lst = []\n",
    "    for value in subset_gems.values():\n",
    "        i = 0\n",
    "        start_idx = int(value[0][1])\n",
    "        total_span = int(value[-1][2]) - start_idx\n",
    "        one_samp_exp_enrich = []\n",
    "        while i < sample_size:\n",
    "            startpos = np.random.randint(low = 0, high = chrom_size - total_span - 1)\n",
    "            current_frag = []\n",
    "            for elem in value:\n",
    "                current_frag.append([chrom, int(startpos + int(elem[1])-start_idx), int(startpos + int(elem[2])-start_idx)])\n",
    "            exp_lst = list(cov.stats(stat = 'max', intervals = current_frag))\n",
    "            exp_enrich = sum(exp_lst)/len(exp_lst)\n",
    "            if int(exp_enrich) == -1:\n",
    "                i -= 1\n",
    "            else:\n",
    "                #exp_enrich_dct.setdefault(key, []).append(exp_enrich)\n",
    "                one_samp_exp_enrich.append(exp_enrich)\n",
    "            i += 1\n",
    "        exp_enrich_lst.append(one_samp_exp_enrich)\n",
    "    return exp_enrich_lst\n",
    "'''\n",
    "'''\n",
    "def random_loc_pe(subset_gems, chrom_size, chrom, sample_size, cov, out):\n",
    "    print(\"In new random_loc_pe\")\n",
    "    out.write(\"In new random_loc_pe\\n\")\n",
    "    np.random.seed(12345)\n",
    "    exp_enrich_lst = []\n",
    "    tot_pseudo_frag = []\n",
    "    for value in subset_gems.values():\n",
    "        start_idx = int(value[0][1])\n",
    "        total_span = int(value[-1][2]) - start_idx\n",
    "        startpos = np.random.randint(low = 0, high = chrom_size - total_span - 1, size = sample_size)\n",
    "        for pos in startpos:\n",
    "            pseudo_frag = []\n",
    "            for elem in value:\n",
    "                pseudo_frag.append([chrom, pos + int(elem[1]) - start_idx, pos + int(elem[2]) - start_idx])\n",
    "            tot_pseudo_frag.append(pseudo_frag)\n",
    "            #out.write(str(tot_pseudo_frag))\n",
    "    print(\"Pseudos created\")\n",
    "    out.write(\"Pseudos created\\n\")\n",
    "    one_d_frags = sum(tot_pseudo_frag, [])\n",
    "    exp_lst = list(cov.stats(stat = 'max', intervals = one_d_frags))\n",
    "    out.write(\"Enrichments found\\n\")\n",
    "    exp_lst_arr = []\n",
    "    # Rearrange exp_lst to keep maximums for the same value grouped together\n",
    "    for validx, value in enumerate(subset_gems.values()):\n",
    "        avg_len = len(value)\n",
    "        exp_lst_arr.append([exp_lst[i:i + avg_len] for i in range(validx*sample_size, validx*sample_size + sample_size, avg_len)])\n",
    "    out.write(\"Enrichments Arranged: \" + str(exp_lst_arr[0]) + \"\\n\")\n",
    "    ## All occurences of -1 in exp_lst:\n",
    "    faulty_idxs = [index for index, enr_val in enumerate(exp_lst_arr) if (-1 in enr_val)]\n",
    "    for badidx in faulty_idxs:\n",
    "        out.write(\"Bad: \" + str(exp_lst_arr[badidx]) + \"\\t\")\n",
    "        while -1 in exp_lst_arr[badidx]:\n",
    "            badfrag = tot_pseudo_frag[badidx]\n",
    "            start_idx = int(badfrag[0][1])\n",
    "            total_span = int(badfrag[-1][2]) - start_idx\n",
    "            startpos2 = np.random.randint(low = 0, high = chrom_size - total_span - 1) - start_idx\n",
    "            better_frag = []\n",
    "            for elem in tot_pseudo_frag[badfrag]:\n",
    "                better_frag.append([chrom, startpos2 + int(elem[1]), startpos2 + int(elem[2])])\n",
    "            exp_lst_arr[badidx] = list(cov.stats(stat = 'max', intervals = better_frag))\n",
    "        out.write(\"Better: \" + str(exp_lst_arr[badidx]) + \"\\n\")\n",
    "    for val in range(0, len(exp_lst_arr), sample_size):\n",
    "        exp_enrich_lst.append([sum(exp_lst_arr[i]) / len(exp_lst_arr[i]) for i in range(val, val + sample_size)])\n",
    "    #exp_enrich = sum(exp_lst)/len(exp_lst)\n",
    "    exp_enrich_lst = 0\n",
    "    return exp_enrich_lst\n",
    "'''\n",
    "\n",
    "\n",
    "def random_loc_pe(subset_gems, chrom_size, chrom, sample_size, cov):\n",
    "    np.random.seed(12345)\n",
    "    exp_enrich_lst = []\n",
    "    for value in subset_gems.values():\n",
    "        start_idx = int(value[0][1])\n",
    "        total_span = int(value[-1][2]) - start_idx\n",
    "        startpos = np.random.randint(low = 0, high = chrom_size - total_span - 1, size = sample_size) - start_idx\n",
    "        current_frag = []\n",
    "        for pos in startpos:\n",
    "            for elem in value:\n",
    "                current_frag.append([chrom, pos + int(elem[1]), pos + int(elem[2])])\n",
    "        exp_lst = list(cov.stats(stat = 'max', intervals = current_frag))\n",
    "        ## All occurences of -1 in exp_lst:\n",
    "        avg_len = len(value)\n",
    "        faulty_idxs = [index for index, enr_val in enumerate(exp_lst) if enr_val == -1]\n",
    "        for badidx in faulty_idxs:\n",
    "            replace_idx = badidx // avg_len\n",
    "            new_exps = exp_lst[replace_idx:replace_idx + avg_len]\n",
    "            while -1 in new_exps:\n",
    "                startpos2 = np.random.randint(low = 0, high = chrom_size - total_span - 1) - start_idx\n",
    "                better_frag = []\n",
    "                for elem in value:\n",
    "                    better_frag.append([chrom, startpos2 + int(elem[1]), startpos2 + int(elem[2])])\n",
    "                new_exps = list(cov.stats(stat = 'max', intervals = better_frag))\n",
    "            for i in range(0, avg_len):\n",
    "                exp_lst[replace_idx + i] = new_exps[i]\n",
    "        exp_enrich_lst.append([sum(exp_lst[i:i + avg_len]) / avg_len for i in range(0, len(exp_lst), avg_len)])\n",
    "        #exp_enrich = sum(exp_lst)/len(exp_lst)\n",
    "    return exp_enrich_lst\n",
    "\n",
    "\n",
    "\n",
    "#def get_raw_pval(obs_frags, obs_span, obs_fraglen, obs_f2f, sample_size, cov, bin_size, chrom_size):\n",
    "def get_raw_pval(exp_enrich, obs_frags, sample_size, cov, strand_type):\n",
    "    \"\"\"\n",
    "    Compute raw p-value for a GEM.\n",
    "    Args:\n",
    "       obs_frags (list of list): [chrom,start,end] for each fragment \n",
    "       obs_span (int): start of leftmost fragment to end of rightmost fragment\n",
    "       obs_fraglen (list): length of each fragment\n",
    "       obs_f2f (list): distance between neighboring fragments\n",
    "       sample_size (int): number of pseudo-GEMs to sample\n",
    "       cov: bedgraph coverage track\n",
    "       bin_size (int): size of the bin used to generate cov\n",
    "       chrom_size (int): size of the chromosome\n",
    "    Returns:\n",
    "       raw_pval (float): raw p-value computed\n",
    "       obs_enrich (int): observed enrichment\n",
    "    \"\"\"\n",
    "    # observed enrichment\n",
    "#    frag_cov = []\n",
    "#    for i in range(len(obs_frags)):\n",
    "#        frag_cov.append(get_mean_cov(obs_frags[i][0], obs_frags[i][1], cov, bin_size))\n",
    "    #frag_cov = list(cov.stats(stat = 'mean', intervals = [[obs_frags[0], int(obs_frags[1]), int(obs_frags[2])]]))\n",
    "    #obs_enrich = cov.stats(stat = 'max', intervals = [[obs_frags[0], int(obs_frags[1]), int(obs_frags[2])]])[0]\n",
    "    if str(strand_type) == \"SE\":\n",
    "        obs_enrich = cov.stats(stat = 'max', intervals =  [[obs_frags[0][0], int(obs_frags[0][1]), int(obs_frags[0][2])]])[0]\n",
    "    else:\n",
    "        current_frag = []\n",
    "        for elem in obs_frags:\n",
    "            current_frag.append([elem[0], int(elem[1]), int(elem[2])])\n",
    "        obs_lst = list(cov.stats(stat = 'max', intervals = current_frag))\n",
    "        #new_lst = [obs_frags[:, 0].tolist(), obs_frags[:, 1].tolist(), obs_frags[:, 2].astype(int).tolist()]\n",
    "        #new_lst = [obs_frags[:, 0].tolist(), obs_frags[:, 1].tolist(), obs_frags[:, 2].tolist()]\n",
    "        #obs_lst = list(cov.stats(stat = 'max', intervals =  [[row[i] for row in new_lst] for i in range(len(new_lst[0]))]))\n",
    "        obs_enrich = sum(obs_lst)/len(obs_lst)\n",
    "        #obs_enrich = max(frag_cov)\n",
    "    # expected enrichment (sampling background)\n",
    "    #startpos = random_loc(chrom_size, obs_span, sample_size)\n",
    "    '''\n",
    "    exp_enrich = []\n",
    "    for k in range(sample_size):\n",
    "        pseudo = pseudo_gem(startpos[k], obs_span, chr_name)\n",
    "        exp = list(cov.stats(stat = 'mean', intervals = pseudo))\n",
    "        exp_enrich.append(sum(exp)/len(exp))\n",
    "        #exp_enrich.append(max(exp))\n",
    "    '''\n",
    "    # write 1000 null (expected, sampled) values; 20191226\n",
    "#    prefix_null = \"_\".join(prefix.split(\"_\")[:-1]) + \"_1000\"\n",
    "#    with open(out_directory + prefix_null + \"_enrichTest_null.txt\", \"a\") as f1:\n",
    "#        f1.write(','.join(map(str, [round(x,1) for x in exp_enrich])) + '\\n')\n",
    "#    f1.close()\n",
    "    # compute raw p-value\n",
    "    #raw_pval = sum(i > obs_enrich for i in exp_enrich)/sample_size\n",
    "    tot = 0\n",
    "    for i in exp_enrich:\n",
    "        tot += (i >= obs_enrich)\n",
    "    raw_pval = tot/sample_size\n",
    "    return(raw_pval, obs_enrich)\n",
    "\n",
    "def get_adj_pval(raw_pval_list, fdr_thresh, method):\n",
    "    \"\"\" \n",
    "    Adjust raw pvalues by Benjamini Hochberg multiple testing adjustment. \n",
    "    Args:\n",
    "       raw_pval_list (list): list of raw p-values (ex: [0.1, 0.04, 0.1])\n",
    "       fdr_thresh (float): false discovery rate (ex: 0.05)\n",
    "       method (string): adjustment method (ex: 'fdr_bh')\n",
    "    Returns:\n",
    "       adj_pval_list (array): array of booleans and adjusted p-values (ex: [0.1, 0.1, 0.1])\n",
    "    \"\"\"\n",
    "    adj_pval_list = multipletests(raw_pval_list, alpha = fdr_thresh, method = method)\n",
    "    return(adj_pval_list)\n",
    "\n",
    "def write_master_result(out_gem_list, out_name):\n",
    "    \"\"\" \n",
    "    Write out significance test results.\n",
    "    Args: \n",
    "       out_gem_list (list): list with 11 items including gem_id, frag_str, p-values, etc.\n",
    "       out_name (string): output file name\n",
    "    Returns:\n",
    "       None\n",
    "    \"\"\"\n",
    "    with open(out_name, 'a') as file1:\n",
    "        header = ['GEM_ID', 'Start Coord', 'End Coord', 'Category', 'Obs', 'rawpval1', 'adjpval1', 'decis1', 'rawpval2', 'adjpval2', 'decis2']\n",
    "        file1.write('\\t'.join(map(str, header)) + '\\n')\n",
    "        for i in range(len(out_gem_list)):\n",
    "            file1.write('\\t'.join(map(str, out_gem_list[i])) + '\\n')\n",
    "\n",
    "def write_output_beds(lst, out_name):\n",
    "    with open(out_name, 'a') as file:\n",
    "        for line in lst:\n",
    "            file.write('\\t'.join(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432db42-0195-4022-8f2a-e1d4b95eecfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de99fb45-814d-4b7a-b8d1-0d12845fa653",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (181225878.py, line 56)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #tracemalloc.start()\n",
    "    total_start = time.time()\n",
    "    argv = os.environ.get('NB_ARGS')\n",
    "    argv = argv.split(\" \")\n",
    "    ### Set parameters ###\n",
    "    library_name = argv[0] ## Library name of our data ##\n",
    "    genome_name = argv[1] ## Name of the reference genome ##\n",
    "    fdr_thresh = float(argv[2])  # should be argument; Benjamini-Hochberg FDR; p-value cutoff ##\n",
    "    chr_lst = argv[3] # should be argument\n",
    "    samp_size = int(argv[4]) ## Number of pseudo-GEMs ##\n",
    "#    bin_size = int(argv[6])\n",
    "    bg_name = argv[5] # bedgraph file name\n",
    "    directory = argv[6]\n",
    "    file_name = argv[7]\n",
    "    strand_type = argv[8] ## Paired End or Single End (PE or SE) ##\n",
    "    \n",
    "    chr_lst = chr_lst.split(\"\\n\")\n",
    "    args_lst = []\n",
    "    for chr_name in chr_lst:\n",
    "        args_lst.append((library_name, genome_name, fdr_thresh, chr_name, samp_size, bg_name, directory, file_name, strand_type))\n",
    "    max_parallel = multiprocessing.cpu_count()\n",
    "    split_chr_lst = []\n",
    "    for i in range(0, len(args_lst), max_parallel):\n",
    "        split_chr_lst.append(args_lst[i:min(i + max_parallel, len(args_lst))])\n",
    "    for elem in split_chr_lst:\n",
    "        print(elem)\n",
    "        with multiprocessing.Pool(processes=max_parallel) as pool:\n",
    "            pool.starmap(defs_v2.full_program, elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51825aa3-3992-482d-8c04-f57d1b2ae05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1534e-5991-417b-982c-3472eb6a5622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e379d1-9700-485a-bbe3-bd765f503e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc0aa7-55b0-498a-8ec2-72f050780084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4bb66-5b1e-4225-b6a6-e625e7d7c53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bdcd2-284e-4985-9de7-1c6c0f662252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc60702-8138-46b4-bc52-83e7dc6d5788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
